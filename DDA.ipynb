{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMT0SfYuQz2InUxpYG2+awg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaiPradeeptha/Drivers-Drving-Behaviour-analysis/blob/main/DDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3B4fPyrWVJ3",
        "outputId": "8c842b9d-10bb-4a1b-acc7-6f38762cfd1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import pygame\n",
        "from scipy.spatial import distance\n",
        "from imutils import face_utils\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib\n",
        "\n",
        "# Load the face detector\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "# Load the landmark predictor using raw string literal\n",
        "predictor = dlib.shape_predictor(\"C:\\Users\\ksaip\\Downloads\\shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "# Initialize eye blink detection parameters\n",
        "EYE_AR_THRESH = 0.25\n",
        "EYE_AR_CONSEC_FRAMES = 20\n",
        "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_68_IDXS[\"left_eye\"]\n",
        "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_68_IDXS[\"right_eye\"]\n",
        "COUNTER = 0\n",
        "ALARM_ON = False\n"
      ],
      "metadata": {
        "id": "T8f4GC2FWhfn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "95db4585-c027-458c-a4ba-56357f0e901f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-19-0cfd6e8670b8>, line 7)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-0cfd6e8670b8>\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    predictor = dlib.shape_predictor(\"C:\\Users\\ksaip\\Downloads\\shape_predictor_68_face_landmarks.dat\")\u001b[0m\n\u001b[0m                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize eye blink detection parameters\n",
        "EYE_AR_THRESH = 0.25\n",
        "EYE_AR_CONSEC_FRAMES = 20\n",
        "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_68_IDXS[\"left_eye\"]\n",
        "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_68_IDXS[\"right_eye\"]\n",
        "COUNTER = 0\n",
        "ALARM_ON = False"
      ],
      "metadata": {
        "id": "N83seawgWl55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize yawn detection parameters\n",
        "MOUTH_AR_THRESH = 0.6\n",
        "YAWN_COUNTER = 0\n",
        "YAWN_FLAG = False"
      ],
      "metadata": {
        "id": "bKs911G_Wo9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "from imutils import face_utils\n",
        "from pygame import mixer\n",
        "import imutils\n",
        "import dlib\n",
        "import cv2\n",
        "\n",
        "\n",
        "mixer.init()\n",
        "mixer.music.load(\"music.wav\")\n",
        "\n",
        "def eye_aspect_ratio(eye):\n",
        "\tA = distance.euclidean(eye[1], eye[5])\n",
        "\tB = distance.euclidean(eye[2], eye[4])\n",
        "\tC = distance.euclidean(eye[0], eye[3])\n",
        "\tear = (A + B) / (2.0 * C)\n",
        "\treturn ear\n",
        "\n",
        "thresh = 0.25\n",
        "frame_check = 20\n",
        "detect = dlib.get_frontal_face_detector()\n",
        "predict = dlib.shape_predictor(\"models/shape_predictor_68_face_landmarks.dat\")\n",
        "\n",
        "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_68_IDXS[\"left_eye\"]\n",
        "(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_68_IDXS[\"right_eye\"]\n",
        "cap=cv2.VideoCapture(0)\n",
        "flag=0\n",
        "while True:\n",
        "\tret, frame=cap.read()\n",
        "\tframe = imutils.resize(frame, width=450)\n",
        "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\tsubjects = detect(gray, 0)\n",
        "\tfor subject in subjects:\n",
        "\t\tshape = predict(gray, subject)\n",
        "\t\tshape = face_utils.shape_to_np(shape)\n",
        "\t\tleftEye = shape[lStart:lEnd]\n",
        "\t\trightEye = shape[rStart:rEnd]\n",
        "\t\tleftEAR = eye_aspect_ratio(leftEye)\n",
        "\t\trightEAR = eye_aspect_ratio(rightEye)\n",
        "\t\tear = (leftEAR + rightEAR) / 2.0\n",
        "\t\tleftEyeHull = cv2.convexHull(leftEye)\n",
        "\t\trightEyeHull = cv2.convexHull(rightEye)\n",
        "\t\tcv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n",
        "\t\tcv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n",
        "\t\tif ear < thresh:\n",
        "\t\t\tflag += 1\n",
        "\t\t\tprint (flag)\n",
        "\t\t\tif flag >= frame_check:\n",
        "\t\t\t\tcv2.putText(frame, \"****************ALERT!****************\", (10, 30),\n",
        "\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\t\t\t\tcv2.putText(frame, \"****************ALERT!****************\", (10,325),\n",
        "\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\t\t\t\tmixer.music.play()\n",
        "\t\telse:\n",
        "\t\t\tflag = 0\n",
        "\tcv2.imshow(\"Frame\", frame)\n",
        "\tkey = cv2.waitKey(1) & 0xFF\n",
        "\tif key == ord(\"q\"):\n",
        "\t\tbreak\n",
        "cv2.destroyAllWindows()\n",
        "cap.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "2Dp-HbQ43g4r",
        "outputId": "f57f779f-8ee2-44b1-ea3e-40768ec7ea7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ALSA: Couldn't open audio device: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8ae59cf87943>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmixer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmusic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"music.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: ALSA: Couldn't open audio device: No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the alert sound using pygame\n",
        "pygame.mixer.init()\n",
        "alert_sound = pygame.mixer.Sound(\"C:\\Users\\ksaip\\Downloads\\music.wav\")"
      ],
      "metadata": {
        "id": "edg4U1jSWrYB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "cc98594c-3e6a-4df0-9283-ac09ef034e07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (<ipython-input-14-69021d80263b>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-69021d80263b>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    alert_sound = pygame.mixer.Sound(\"C:\\Users\\ksaip\\Downloads\\music.wav\")\u001b[0m\n\u001b[0m                                                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the alert message timer\n",
        "ALERT_MESSAGE_DURATION = 4  # in seconds\n",
        "alert_message_start_time = 0"
      ],
      "metadata": {
        "id": "51nJDdpNWt66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eye_aspect_ratio(eye):\n",
        "    A = distance.euclidean(eye[1], eye[5])\n",
        "    B = distance.euclidean(eye[2], eye[4])\n",
        "    C = distance.euclidean(eye[0], eye[3])\n",
        "    ear = (A + B) / (2.0 * C)\n",
        "    return ear"
      ],
      "metadata": {
        "id": "e26jBw8ZWwcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mouth_aspect_ratio(mouth):\n",
        "    A = euclidean_dist(mouth[13], mouth[19])\n",
        "    B = euclidean_dist(mouth[14], mouth[18])\n",
        "    C = euclidean_dist(mouth[15], mouth[17])\n",
        "    mar = (A + B + C) / (3.0 * euclidean_dist(mouth[12], mouth[16]))\n",
        "    return mar"
      ],
      "metadata": {
        "id": "QXXV7RMZW0NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mouth_aspect_ratio(mouth):\n",
        "    A = euclidean_dist(mouth[13], mouth[19])\n",
        "    B = euclidean_dist(mouth[14], mouth[18])\n",
        "    C = euclidean_dist(mouth[15], mouth[17])\n",
        "    mar = (A + B + C) / (3.0 * euclidean_dist(mouth[12], mouth[16]))\n",
        "    return mar"
      ],
      "metadata": {
        "id": "j5uPdVH2W3D0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start video stream\n",
        "cap = cv2.VideoCapture(0)  # Use 0 for the default camera, or replace with a video file path"
      ],
      "metadata": {
        "id": "ziUnrk-GW6ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break"
      ],
      "metadata": {
        "id": "DDDrE9A2W9SH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Convert frame to grayscale\n",
        "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
      ],
      "metadata": {
        "id": "sOSslaB9XAV4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "3b194ba1-f6de-473e-8706-ef2d9d4864d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-09f89b86dfe0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Convert frame to grayscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect faces in the grayscale frame\n",
        "faces = detector(gray, 0)"
      ],
      "metadata": {
        "id": "7fx1Pb-fXDIa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "dbb920e2-eaef-4a09-f543-c7273e94146e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'gray' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-36d79c32f8c6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Detect faces in the grayscale frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'gray' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for face in faces:\n",
        "    shape = predictor(gray, face)\n",
        "    shape = face_utils.shape_to_np(shape)"
      ],
      "metadata": {
        "id": "VAprwIW2XHJA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "f99a6939-a861-413f-d040-ca8531c37f38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'faces' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5cf29f05ee51>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mface\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'faces' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Extract eye landmarks\n",
        "leftEye = shape[lStart:lEnd]\n",
        "rightEye = shape[rStart:rEnd]"
      ],
      "metadata": {
        "id": "O7Vy1VC0XRzX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "2eaab14f-d5ea-487e-9ba4-a7782301ead2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shape' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-6789b3584d91>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract eye landmarks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mleftEye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlStart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlEnd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrightEye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrStart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mrEnd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shape' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate eye aspect ratio (EAR)\n",
        "leftEAR = eye_aspect_ratio(leftEye)\n",
        "rightEAR = eye_aspect_ratio(rightEye)\n",
        "ear = (leftEAR + rightEAR) / 2.0"
      ],
      "metadata": {
        "id": "aq0mWHITXUvB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "edb54f5b-7b02-4e8e-f162-03c135ec57a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'leftEye' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-7bc6d23458a3>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calculate eye aspect ratio (EAR)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mleftEAR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meye_aspect_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleftEye\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mrightEAR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meye_aspect_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrightEye\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mear\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mleftEAR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrightEAR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'leftEye' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Detect eye blink\n",
        "        if ear < EYE_AR_THRESH:\n",
        "            COUNTER += 1\n",
        "\n",
        "            if COUNTER >= EYE_AR_CONSEC_FRAMES:\n",
        "                if not ALARM_ON:\n",
        "                    ALARM_ON = True\n",
        "                    alert_sound.play()\n",
        "                    alert_message_start_time = time.time()\n",
        "\n",
        "                cv2.putText(frame, \"You are drowsy!\", (10, 60),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "        else:\n",
        "            COUNTER = 0\n",
        "            ALARM_ON = False"
      ],
      "metadata": {
        "id": "ZloCx2ocXXwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract mouth landmarks (from points 48 to 67)\n",
        " mouth = shape[48:68]"
      ],
      "metadata": {
        "id": "oOHP8ACRXerC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mouth aspect ratio (MAR)\n",
        " mouth_ar = mouth_aspect_ratio(mouth)"
      ],
      "metadata": {
        "id": "CmSAXIj4Xjxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Detect yawn\n",
        "        if mouth_ar < MOUTH_AR_THRESH:\n",
        "            if not YAWN_FLAG:\n",
        "                YAWN_COUNTER += 1\n",
        "                YAWN_FLAG = True\n",
        "\n",
        "                # Play the alert sound and set the alert message timer when a yawn is detected\n",
        "                alert_sound.play()\n",
        "                alert_message_start_time = time.time()\n",
        "\n",
        "        else:\n",
        "            YAWN_FLAG = False"
      ],
      "metadata": {
        "id": "VRYN03LwXvjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Draw facial landmarks on eyebrows, jaw, and chin\n",
        "        jaw = shape[0:17]\n",
        "        right_eyebrow = shape[17:22]\n",
        "        left_eyebrow = shape[22:27]\n",
        "\n",
        "        for (x, y) in jaw:\n",
        "            cv2.circle(frame, (x, y), 2, (0, 0, 255), -1)  # Red color for jaw landmarks\n",
        "        for (x, y) in right_eyebrow:\n",
        "            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)  # Green color for right eyebrow landmarks\n",
        "        for (x, y) in left_eyebrow:\n",
        "            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)  # Green color for left eyebrow landmarks"
      ],
      "metadata": {
        "id": "pbm3gR9MX0_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Draw the eye landmarks as green points\n",
        "        for (x, y) in leftEye:\n",
        "            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)\n",
        "        for (x, y) in rightEye:\n",
        "            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)"
      ],
      "metadata": {
        "id": "sOdFCFLx3dza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Draw the mouth landmarks as green points\n",
        "        for (x, y) in mouth:\n",
        "            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)"
      ],
      "metadata": {
        "id": "tyO_X4cLX6s3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Draw the yawn count on the frame\n",
        "        cv2.putText(frame, f\"Yawns: {YAWN_COUNTER}\", (10, 30),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)"
      ],
      "metadata": {
        "id": "VC87SbqZX9nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Display the alert message for 4 seconds\n",
        "        if time.time() - alert_message_start_time < ALERT_MESSAGE_DURATION:\n",
        "            cv2.putText(frame, \"Take a break!\", (10, 90),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n"
      ],
      "metadata": {
        "id": "BZGdXk7dYAJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the frame\n",
        "    cv2.imshow(\"Frame\", frame)"
      ],
      "metadata": {
        "id": "jqC_7nSDYC1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Exit on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break"
      ],
      "metadata": {
        "id": "uUQ-ejVkYFVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Release video capture and close all windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Oq9GPhCQYHz0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}